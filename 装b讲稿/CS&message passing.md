# Compressed Sensing

## What is compressed sensing?

(1) a novel approach to data acuisition

在应用上来说，新的信息获取的方式

(2) a sparse signal recovery mechanism

在解决问题上来说，是一个稀疏信号恢复或者重构的方法

## How many measurements are needed?

从经典意义上，如果要采集一个完整的信号，需要多大的代价？也就是多大的采样率。

(1) Shannon Sampling theorem（从经典的采样定理告诉我们）

Sampling rate must be twice the highest freqency
香农采样定理说，如果想要完整的信号，采样率至少最高频率的两倍

(2) 线性代数（如果把问题简化一些，从线性代数角度上来看）

假设我们有一个n维的信号，线性度量的方式来说，在信号前面乘以一个线性矩阵
measurements = dimension of signal : y = Ax。 y就是我们最终得到的样本。

这个时候，如果我们要重构n维信号的话，我们需要n次测量。也就说，如果我们有n维的信号，至少要测量n次。

## 实际采集完是怎么处理的呢？

（1）首先通过某种方式得到信号，进行n次的采样
（2）然后进行一定成对的压缩，只有m个有用的信号
（3）传输过去之后，收到的信号，我们进行一次解压缩，然后还原出原来的信号。

这个过程中，最核心的是有用的m维信号，而不是初始的n维。

这个过程有一个问题，一开始费劲采集了n维信号，但其实在过程中，真正用到的只是中间的一部分，这就造成一种浪费。既然我们真正用到的只有m。
那么能不能在采样的时候，直接采集这m个有用的信号。这样就省去了先采样，后压缩的过程。这个就是压缩感知问题的由来。

## 回到线性方程组的问题


如果按照刚才的想法，希望用更少的采集量，来获取我们原始的信号。行数小于列数，这样就可以实现很少的采样率来获得原始信号。数学上就是要解
一个欠定方程组。欠定方程可能有无穷多个解。但是一般来说，要重构的x信号不是一个没有规则的信号，我们实际去研究一个图片或者一段语音，都是有结构的。

比如一个图片进行小波变换之后，有可能小波系数绝大多数都是0。如果我们把接近0 或者0的系数去掉，而只是保留相对比较大的系数。 
这些较大的系数只占信息量的百分之几，百分之2，3之类的。我们只用这百分之2点几系数，做小波逆变换来重构信号。

所以这样一个结构说明一个问题就是，处理的图片，包括语音也是类似的。他们都有稀疏性。

稀疏性就是信号经过一系列变换之后，绝大多数系数是0，这样的信号就是有稀疏性的信号。


## 稀疏信号恢复

我们恢复的不是一个泛泛意义上的信号。实际上是重构一个稀疏信号。也就x中，大多数信号都是0。只有少部分非零。

在这种稀疏信号的情况下，我们有没有一种可能，通过解欠定方程组把这个信号重构出来呢？这就是压缩感知真正要解决的问题。

## 这个问题怎么来解

主流的两种方式

### 法1: 优化optimization

思路1: 找一个最稀疏的解。表示最稀疏，找的是x的l0范数。问题是，很难求解，不连续。
思路2: l1范数，凸优化问题。1范数绝对值是凸函数。（basis pursuit)

2. rip(理论上什么时候l1可以重构出原始信号）


3. 但是l1 范数效果远达不到，对于很稀疏的信号的时候，就失真了。也就是说，l1范数的实际测量数，要高于理论下限的。

### 有没有一个方式，可以用更少的测量来重构出原始信号呢？

信息传播方法

### 法2:统计推断 statistical inference

1. 从统计推断的角度我们来重新看压缩感知的这个问题

压缩感知这个问题实际上来看，我们真正的问题是要求解未知的稀疏的信号x，我们已知y（样本）， A（测量矩阵）。如何通过y和A推断出x。这就是经典的统计推断问题。


2. 统计推断经典的理论(Bayes' theorem)

<img width="666" alt="WeChat742d8839caa2bd1b5166b873c6db2386" src="https://user-images.githubusercontent.com/69283174/154221428-68180aef-ad4a-4d1b-8163-c5df990fec64.png">

<img width="666" alt="WeChata993ce902924763dab5c0a103ed5b512" src="https://user-images.githubusercontent.com/69283174/154221668-4616bf12-e839-4504-ac9e-96c67e43e055.png">

首先我们假设信号之间都是独立的，所以可以连乘

<img width="666" alt="WeChat46eb52c7a54518d57124ebd20265efdd" src="https://user-images.githubusercontent.com/69283174/154222176-e652cede-f47e-4159-892a-b77d023cb82c.png">



这个概率和统计物理有很紧密的联系的。也就是说统计推断和统计物理有很紧密的联系的。

3. 从贝叶斯的角度来说，基于后验概率怎么去推测出信号x

（1）MAP（lasso): 最大后验，取最大后验概率最大的x来作为x
(2) mmse: 使得实际x和真实x的差的平凡和最小。从统计贝叶斯角度来说，mmse方法是贝叶斯最优的，也就是均方误差最小的量，也就是最接近真实信号的量。

<img width="666" alt="WeChata5d101afbbcc129c3632b4836d218e56" src="https://user-images.githubusercontent.com/69283174/154223125-b45e76af-d6e1-4802-a8c6-d3dbff99347a.png">



对于高维度来说，计算边缘分布是很困难的。

4.提出了很多近似的方法来估计边缘分布：mcmc(维度高也耗时），Belief Propagation method（信念传播）

# 信息传播

## 几个经典的信息传递算法在压缩感知

AMP（09），第一次把消息算法用在压缩感知上，用的map的统计推断的方式。与凸优化算法相比，这个算法可以解析的，也就是说，可以精确
刻画每个迭代步的状态。这个是一般传统优化算法没有的性质。

## BP怎么实现的? 

BP最重要的一个假设是
 
