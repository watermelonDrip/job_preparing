# AMP

AMP 最开始用在压缩感知上。后来AMP用在标准线性回归上。

标准线性回归问题是从噪声线性观测值Y= AX0+W恢复向量X0。
Donoho、Maleki和Muntali提出的近似消息传递（AMP）算法是一种计算效率很高的迭代方法，它对SLR具有显著的性质：对于大I.I.D.亚高斯矩阵A，其每次迭代行为的严格特征是标量状态演化，其不动点在唯一时是Bayes最优的。
然而，AMP算法是脆弱的，因为即使是与i.i.d.亚高斯模型的微小偏差也会导致算法发散。提出了UAMP算法， 其中U表示的是酉变换。从实验室和理论证明了UAMP 适用于更广泛的一类大随机矩阵a, 特别是对于 
行相关性比较强的矩阵 或者欠秩的矩阵， 收敛速度快并且稳定。

# SBL
 
稀疏贝叶斯学习(Sparse Bayesian Learning, SBL)最初作为一种机器学习算法由 Tipping 于 2001 年 前后提出[Tipping2001]，
随后被引入到稀疏信号恢复/压缩感知领域[Wipf2004,Ji2008]。刚刚说对于矩阵不好的时候效果不好，SBL 表现很好。因此，在雷达追踪，波达方向估计， 脑源定位，特征提取，功率谱估计等一些列领域，SBL 都具备显著的优势。

作为一种贝叶斯算法，SBL 算法对利用这些解的结构信息 提供了更多的灵活性。这种灵活性最主要来自于 SBL 采用参数化的高斯分布为解的先验分布。 其实也可以
 
